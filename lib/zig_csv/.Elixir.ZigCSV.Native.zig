// this code is autogenerated, do not check it into to your code repository

// ref lib/zig_csv/native.ex:12
const std = @import("std");
const beam = @import("beam");
const e = @import("erl_nif");

// ============================================================================
// Core Types
// ============================================================================

const Config = struct {
    separator: u8,
    escape: u8,
};

const FieldBoundary = packed struct {
    start: u32,
    end: u32,
    needs_unescape: bool,
};

// ============================================================================
// Streaming Parser Resource (for stateful streaming across NIF calls)
// ============================================================================

pub const StreamingParserState = struct {
    buffer: std.ArrayListUnmanaged(u8),
    separator: u8,
    escape: u8,

    const Self = @This();

    pub fn init(separator: u8, escape: u8) Self {
        return Self{
            .buffer = std.ArrayListUnmanaged(u8){},
            .separator = separator,
            .escape = escape,
        };
    }

    pub fn deinit(self: *Self) void {
        self.buffer.deinit(beam.allocator);
    }
};

pub const StreamingParserResource = beam.Resource(StreamingParserState, @import("root"), .{});

// ============================================================================
// Memory Tracking (Feature Flag)
// ============================================================================
//
// Set ZIGCSV_MEMORY_TRACKING=1 to enable memory tracking for benchmarks.
// When disabled (default), tracking functions return 0 with zero overhead.
//
// Usage:
//   # Enable tracking for benchmarks
//   ZIGCSV_MEMORY_TRACKING=1 mix compile --force
//
//   # In your code
//   ZigCSV.Native.reset_zig_memory_stats()
//   result = CSV.parse_string(large_csv)
//   {current, peak} = ZigCSV.Native.get_zig_memory()
//

// Compile-time feature flag for memory tracking
// To enable: Set to true and recompile with `mix compile --force`
// When false (default), all tracking code is eliminated by dead code elimination,
// resulting in zero runtime overhead.
const memory_tracking_enabled = false;

var memory_current: usize = 0;
var memory_peak: usize = 0;

pub fn get_zig_memory() struct { usize, usize } {
    return .{ memory_current, memory_peak };
}

pub fn get_zig_memory_peak() usize {
    return memory_peak;
}

pub fn reset_zig_memory_stats() void {
    memory_current = 0;
    memory_peak = 0;
}

// Tracking allocator - only compiled when memory_tracking_enabled
const TrackingAllocator = struct {
    parent: std.mem.Allocator,

    pub fn getAllocator(self: *@This()) std.mem.Allocator {
        return .{
            .ptr = self,
            .vtable = &vtable,
        };
    }

    const vtable = std.mem.Allocator.VTable{
        .alloc = trackingAlloc,
        .resize = trackingResize,
        .remap = trackingRemap,
        .free = trackingFree,
    };

    fn trackingAlloc(ctx: *anyopaque, len: usize, ptr_align: std.mem.Alignment, ret_addr: usize) ?[*]u8 {
        const self: *TrackingAllocator = @ptrCast(@alignCast(ctx));
        const result = self.parent.rawAlloc(len, ptr_align, ret_addr);
        if (memory_tracking_enabled and result != null) {
            memory_current += len;
            if (memory_current > memory_peak) {
                memory_peak = memory_current;
            }
        }
        return result;
    }

    fn trackingResize(ctx: *anyopaque, buf: []u8, buf_align: std.mem.Alignment, new_len: usize, ret_addr: usize) bool {
        const self: *TrackingAllocator = @ptrCast(@alignCast(ctx));
        const old_len = buf.len;
        if (self.parent.rawResize(buf, buf_align, new_len, ret_addr)) {
            if (memory_tracking_enabled) {
                if (new_len > old_len) {
                    memory_current += (new_len - old_len);
                    if (memory_current > memory_peak) {
                        memory_peak = memory_current;
                    }
                } else {
                    memory_current -= (old_len - new_len);
                }
            }
            return true;
        }
        return false;
    }

    fn trackingFree(ctx: *anyopaque, buf: []u8, buf_align: std.mem.Alignment, ret_addr: usize) void {
        const self: *TrackingAllocator = @ptrCast(@alignCast(ctx));
        if (memory_tracking_enabled and memory_current >= buf.len) {
            memory_current -= buf.len;
        }
        self.parent.rawFree(buf, buf_align, ret_addr);
    }

    fn trackingRemap(ctx: *anyopaque, buf: []u8, buf_align: std.mem.Alignment, new_len: usize, ret_addr: usize) ?[*]u8 {
        const self: *TrackingAllocator = @ptrCast(@alignCast(ctx));
        const old_len = buf.len;
        const result = self.parent.rawRemap(buf, buf_align, new_len, ret_addr);
        if (memory_tracking_enabled and result != null) {
            if (new_len > old_len) {
                memory_current += (new_len - old_len);
                if (memory_current > memory_peak) {
                    memory_peak = memory_current;
                }
            } else {
                memory_current -= (old_len - new_len);
            }
        }
        return result;
    }
};

var tracking_allocator_instance = TrackingAllocator{ .parent = beam.allocator };
const allocator = tracking_allocator_instance.getAllocator();

// ============================================================================
// SIMD Utilities - 32-byte vectors (AVX2 / 2x NEON)
// ============================================================================

const VECTOR_SIZE = 32;
const CharVector = @Vector(VECTOR_SIZE, u8);
const MaskType = u32;

inline fn simdFindAny3(haystack: []const u8, a: u8, b: u8, c: u8) ?usize {
    var i: usize = 0;

    // Process 32 bytes at a time
    while (i + VECTOR_SIZE <= haystack.len) {
        const chunk: CharVector = haystack[i..][0..VECTOR_SIZE].*;
        const matches = (chunk == @as(CharVector, @splat(a))) |
                        (chunk == @as(CharVector, @splat(b))) |
                        (chunk == @as(CharVector, @splat(c)));

        if (@reduce(.Or, matches)) {
            const mask: MaskType = @bitCast(matches);
            return i + @ctz(mask);
        }
        i += VECTOR_SIZE;
    }

    // Scalar fallback for remainder
    while (i < haystack.len) {
        const c_byte = haystack[i];
        if (c_byte == a or c_byte == b or c_byte == c) return i;
        i += 1;
    }

    return null;
}

inline fn simdFindByte(haystack: []const u8, target: u8) ?usize {
    var i: usize = 0;

    while (i + VECTOR_SIZE <= haystack.len) {
        const chunk: CharVector = haystack[i..][0..VECTOR_SIZE].*;
        const matches = chunk == @as(CharVector, @splat(target));

        if (@reduce(.Or, matches)) {
            const mask: MaskType = @bitCast(matches);
            return i + @ctz(mask);
        }
        i += VECTOR_SIZE;
    }

    while (i < haystack.len) {
        if (haystack[i] == target) return i;
        i += 1;
    }

    return null;
}

inline fn simdCountByte(haystack: []const u8, target: u8) usize {
    var count: usize = 0;
    var i: usize = 0;

    while (i + VECTOR_SIZE <= haystack.len) {
        const chunk: CharVector = haystack[i..][0..VECTOR_SIZE].*;
        const matches = chunk == @as(CharVector, @splat(target));
        count += @popCount(@as(MaskType, @bitCast(matches)));
        i += VECTOR_SIZE;
    }

    while (i < haystack.len) {
        if (haystack[i] == target) count += 1;
        i += 1;
    }

    return count;
}

// ============================================================================
// Fast Two-Pass Parser
// ============================================================================

// Phase 1: Build index of all field boundaries
fn buildIndex(
    input: []const u8,
    config: Config,
    boundaries: []FieldBoundary,
    row_starts: []u32,
) struct { field_count: usize, row_count: usize } {
    var pos: usize = 0;
    var field_idx: usize = 0;
    var row_idx: usize = 0;

    row_starts[0] = 0;

    while (pos < input.len and field_idx < boundaries.len) {
        const start = pos;

        if (pos < input.len and input[pos] == config.escape) {
            // Quoted field
            pos += 1;
            const content_start = pos;
            var needs_unescape = false;

            while (pos < input.len) {
                const remaining = input[pos..];
                if (simdFindByte(remaining, config.escape)) |offset| {
                    pos += offset + 1;
                    if (pos < input.len and input[pos] == config.escape) {
                        needs_unescape = true;
                        pos += 1;
                    } else {
                        break;
                    }
                } else {
                    pos = input.len;
                    break;
                }
            }

            boundaries[field_idx] = .{
                .start = @intCast(content_start),
                .end = @intCast(if (pos > 0 and pos <= input.len and (pos == input.len or input[pos - 1] == config.escape)) pos - 1 else pos),
                .needs_unescape = needs_unescape,
            };
        } else {
            // Unquoted field - use SIMD to find delimiter
            const remaining = input[start..];
            if (simdFindAny3(remaining, config.separator, '\n', '\r')) |offset| {
                pos = start + offset;
            } else {
                pos = input.len;
            }

            boundaries[field_idx] = .{
                .start = @intCast(start),
                .end = @intCast(pos),
                .needs_unescape = false,
            };
        }

        field_idx += 1;

        // Handle field/row separator
        if (pos < input.len) {
            if (input[pos] == config.separator) {
                pos += 1;
            } else if (input[pos] == '\r' or input[pos] == '\n') {
                if (input[pos] == '\r') pos += 1;
                if (pos < input.len and input[pos] == '\n') pos += 1;
                row_idx += 1;
                if (row_idx < row_starts.len) {
                    row_starts[row_idx] = @intCast(field_idx);
                }
            }
        }
    }

    // Handle last row if no trailing newline
    if (field_idx > 0 and (row_idx == 0 or row_starts[row_idx] != field_idx)) {
        row_idx += 1;
    }

    return .{ .field_count = field_idx, .row_count = row_idx };
}

// Unescape a quoted field (remove doubled escape chars)
fn unescapeInPlace(input: []const u8, escape: u8, output: []u8) usize {
    var write_idx: usize = 0;
    var read_idx: usize = 0;

    while (read_idx < input.len) {
        if (input[read_idx] == escape and read_idx + 1 < input.len and input[read_idx + 1] == escape) {
            output[write_idx] = escape;
            write_idx += 1;
            read_idx += 2;
        } else {
            output[write_idx] = input[read_idx];
            write_idx += 1;
            read_idx += 1;
        }
    }

    return write_idx;
}

// Phase 2: Create BEAM terms from index (uses global tracking allocator)
fn createTerms(
    input: []const u8,
    config: Config,
    boundaries: []const FieldBoundary,
    row_starts: []const u32,
    row_count: usize,
    field_count: usize,
) beam.term {
    // Allocate row terms array
    const row_terms = allocator.alloc(beam.term, row_count) catch return beam.make(.@"error", .{});
    defer allocator.free(row_terms);

    // Temp buffer for unescaping (reused across fields)
    var unescape_buf: [65536]u8 = undefined;

    var row_idx: usize = 0;
    while (row_idx < row_count) : (row_idx += 1) {
        const start_field = row_starts[row_idx];
        const end_field = if (row_idx + 1 < row_count) row_starts[row_idx + 1] else @as(u32, @intCast(field_count));
        const fields_in_row = end_field - start_field;

        // Allocate field terms for this row
        const field_terms = allocator.alloc(beam.term, fields_in_row) catch return beam.make(.@"error", .{});
        defer allocator.free(field_terms);

        var field_offset: u32 = 0;
        while (field_offset < fields_in_row) : (field_offset += 1) {
            const boundary = boundaries[start_field + field_offset];
            const raw_field = input[boundary.start..boundary.end];

            if (boundary.needs_unescape) {
                const len = unescapeInPlace(raw_field, config.escape, &unescape_buf);
                field_terms[field_offset] = beam.make(unescape_buf[0..len], .{});
            } else {
                field_terms[field_offset] = beam.make(raw_field, .{});
            }
        }

        row_terms[row_idx] = beam.make(field_terms, .{});
    }

    return beam.make(row_terms, .{});
}

// Main optimized parser - using cons-style list building
// SmallVec-like behavior: uses stack for small files, spills to heap for large files
fn parseCSVFast(input: []const u8, config: Config) beam.term {
    if (input.len == 0) {
        return beam.make(&[_]beam.term{}, .{});
    }

    // Uses global tracking allocator

    // Stack buffer for row terms (fast path for files up to 100K rows)
    const STACK_ROWS = 102400;
    var stack_rows: [STACK_ROWS]beam.term = undefined;

    // Heap buffer for overflow (SmallVec-like spill)
    var heap_rows: ?[]beam.term = null;
    var heap_capacity: usize = 0;
    defer if (heap_rows) |h| allocator.free(h);

    var row_count: usize = 0;

    // Stack buffer for field terms per row (support up to 1024 columns)
    var field_buf: [1024]beam.term = undefined;
    // Stack buffer for unescaping
    var unescape_buf: [65536]u8 = undefined;

    var pos: usize = 0;

    while (pos <= input.len) {
        var field_count: usize = 0;
        var row_done = false;

        // Parse fields in this row
        while (!row_done and field_count < field_buf.len) {
            if (pos < input.len and input[pos] == config.escape) {
                // Quoted field
                pos += 1;
                const content_start = pos;
                var needs_unescape = false;

                while (pos < input.len) {
                    const remaining = input[pos..];
                    if (simdFindByte(remaining, config.escape)) |offset| {
                        pos += offset + 1;
                        if (pos < input.len and input[pos] == config.escape) {
                            needs_unescape = true;
                            pos += 1;
                        } else {
                            break;
                        }
                    } else {
                        pos = input.len;
                        break;
                    }
                }

                const content_end = if (pos > content_start) pos - 1 else content_start;
                const raw = input[content_start..content_end];

                if (needs_unescape) {
                    const len = unescapeInPlace(raw, config.escape, &unescape_buf);
                    field_buf[field_count] = beam.make(unescape_buf[0..len], .{});
                } else {
                    field_buf[field_count] = beam.make(raw, .{});
                }
            } else {
                // Unquoted field - SIMD scan
                const start = pos;
                if (start < input.len) {
                    const remaining = input[start..];
                    if (simdFindAny3(remaining, config.separator, '\n', '\r')) |offset| {
                        pos = start + offset;
                    } else {
                        pos = input.len;
                    }
                    field_buf[field_count] = beam.make(input[start..pos], .{});
                } else {
                    // Empty field at end of input
                    field_buf[field_count] = beam.make("", .{});
                }
            }

            field_count += 1;

            // Check for separator or end of row
            if (pos < input.len) {
                if (input[pos] == config.separator) {
                    pos += 1;
                    // Continue to next field
                } else if (input[pos] == '\r' or input[pos] == '\n') {
                    if (input[pos] == '\r') pos += 1;
                    if (pos < input.len and input[pos] == '\n') pos += 1;
                    row_done = true;
                }
            } else {
                // End of input
                row_done = true;
            }
        }

        if (field_count > 0) {
            // Build field list using cons cells
            var field_list = beam.make_empty_list(.{});
            var i: usize = field_count;
            while (i > 0) {
                i -= 1;
                field_list = beam.make_list_cell(field_buf[i], field_list, .{});
            }

            // SmallVec-like storage: stack first, spill to heap if needed
            if (row_count < STACK_ROWS) {
                // Fast path: store on stack
                stack_rows[row_count] = field_list;
            } else {
                // Slow path: spill to heap
                if (heap_rows == null) {
                    // First spill: allocate heap and copy stack contents
                    heap_capacity = STACK_ROWS * 2;
                    heap_rows = allocator.alloc(beam.term, heap_capacity) catch {
                        // Allocation failed, return what we have
                        break;
                    };
                    @memcpy(heap_rows.?[0..STACK_ROWS], &stack_rows);
                } else if (row_count >= heap_capacity) {
                    // Need to grow heap buffer
                    const new_capacity = heap_capacity * 2;
                    heap_rows = allocator.realloc(heap_rows.?, new_capacity) catch break;
                    heap_capacity = new_capacity;
                }
                heap_rows.?[row_count] = field_list;
            }
            row_count += 1;
        }

        // Exit if we've consumed all input
        if (pos >= input.len) break;
    }

    // Build row list using cons cells from the appropriate buffer
    var row_list = beam.make_empty_list(.{});
    var i: usize = row_count;

    if (heap_rows) |heap| {
        // Large file: read from heap buffer
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(heap[i], row_list, .{});
        }
    } else {
        // Small file: read from stack buffer
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(stack_rows[i], row_list, .{});
        }
    }

    return row_list;
}

// Basic parser (non-SIMD, for comparison)
fn parseCSVBasic(input: []const u8, config: Config) beam.term {
    if (input.len == 0) {
        return beam.make(&[_]beam.term{}, .{});
    }

    // Uses global tracking allocator

    // Count rows
    var row_count: usize = 0;
    var i: usize = 0;
    while (i < input.len) : (i += 1) {
        if (input[i] == '\n') row_count += 1;
    }
    if (input.len > 0 and input[input.len - 1] != '\n') row_count += 1;

    const row_terms = allocator.alloc(beam.term, row_count) catch return beam.make(.@"error", .{});
    defer allocator.free(row_terms);

    var pos: usize = 0;
    var row_idx: usize = 0;

    while (pos < input.len and row_idx < row_count) {
        // Count fields in row
        var field_count: usize = 1;
        var scan = pos;
        var in_quotes = false;

        while (scan < input.len) {
            const c = input[scan];
            if (in_quotes) {
                if (c == config.escape) {
                    if (scan + 1 < input.len and input[scan + 1] == config.escape) {
                        scan += 2;
                        continue;
                    }
                    in_quotes = false;
                }
            } else {
                if (c == config.escape) {
                    in_quotes = true;
                } else if (c == config.separator) {
                    field_count += 1;
                } else if (c == '\n' or c == '\r') {
                    break;
                }
            }
            scan += 1;
        }

        const field_terms = allocator.alloc(beam.term, field_count) catch return beam.make(.@"error", .{});
        defer allocator.free(field_terms);

        var field_idx: usize = 0;
        while (pos < input.len and field_idx < field_count) {
            const start = pos;
            var needs_unescape = false;
            var content_start = start;
            var content_end = start;

            if (pos < input.len and input[pos] == config.escape) {
                // Quoted field
                pos += 1;
                content_start = pos;
                while (pos < input.len) {
                    if (input[pos] == config.escape) {
                        pos += 1;
                        if (pos < input.len and input[pos] == config.escape) {
                            needs_unescape = true;
                            pos += 1;
                        } else {
                            content_end = pos - 1;
                            break;
                        }
                    } else {
                        pos += 1;
                    }
                }
                if (pos >= input.len) content_end = pos;
            } else {
                // Unquoted field
                while (pos < input.len) {
                    const c = input[pos];
                    if (c == config.separator or c == '\n' or c == '\r') break;
                    pos += 1;
                }
                content_start = start;
                content_end = pos;
            }

            const raw = input[content_start..content_end];

            if (needs_unescape) {
                const buf = allocator.alloc(u8, raw.len) catch return beam.make(.@"error", .{});
                defer allocator.free(buf);
                const len = unescapeInPlace(raw, config.escape, buf);
                field_terms[field_idx] = beam.make(buf[0..len], .{});
            } else {
                field_terms[field_idx] = beam.make(raw, .{});
            }

            field_idx += 1;

            if (pos < input.len) {
                if (input[pos] == config.separator) {
                    pos += 1;
                } else if (input[pos] == '\r' or input[pos] == '\n') {
                    if (input[pos] == '\r') pos += 1;
                    if (pos < input.len and input[pos] == '\n') pos += 1;
                    break;
                }
            }
        }

        row_terms[row_idx] = beam.make(field_terms, .{});
        row_idx += 1;
    }

    return beam.make(row_terms[0..row_idx], .{});
}

// ============================================================================
// Strategy A: Basic Parser
// ============================================================================

pub fn parse_string(input: []const u8) beam.term {
    return parse_string_with_config(input, ',', '"');
}

pub fn parse_string_with_config(input: []const u8, separator: u8, escape: u8) beam.term {
    return parseCSVBasic(input, Config{ .separator = separator, .escape = escape });
}

// ============================================================================
// Strategy B: SIMD Parser (optimized two-pass)
// ============================================================================

pub fn parse_string_fast(input: []const u8) beam.term {
    return parse_string_fast_with_config(input, ',', '"');
}

pub fn parse_string_fast_with_config(input: []const u8, separator: u8, escape: u8) beam.term {
    return parseCSVFast(input, Config{ .separator = separator, .escape = escape });
}

// ============================================================================
// Strategy C: Indexed Parser
// ============================================================================

pub fn parse_string_indexed(input: []const u8) beam.term {
    return parse_string_indexed_with_config(input, ',', '"');
}

pub fn parse_string_indexed_with_config(input: []const u8, separator: u8, escape: u8) beam.term {
    return parseCSVFast(input, Config{ .separator = separator, .escape = escape });
}

// ============================================================================
// Strategy D: Streaming Parser (Resource-based)
// Uses NIF resources to maintain stateful parser across calls.
// ============================================================================

pub fn streaming_new() StreamingParserResource {
    return streaming_new_with_config(',', '"');
}

pub fn streaming_new_with_config(separator: u8, escape: u8) StreamingParserResource {
    const state = StreamingParserState.init(separator, escape);
    return StreamingParserResource.create(state, .{}) catch {
        // This shouldn't fail in practice, but handle it
        @panic("Failed to create streaming parser resource");
    };
}

// Returns tuple: {parsed_rows_list, buffer_size}
pub fn streaming_feed(parser: StreamingParserResource, chunk: []const u8) struct { beam.term, usize } {
    var state = parser.unpack();

    // Append chunk to buffer
    state.buffer.appendSlice(beam.allocator, chunk) catch {
        parser.update(state);
        return .{ beam.make(&[_]beam.term{}, .{}), state.buffer.items.len };
    };

    // Find last complete row (last newline not inside quotes)
    const data = state.buffer.items;
    var last_complete: usize = 0;
    var in_quotes = false;
    var i: usize = 0;

    while (i < data.len) {
        if (data[i] == state.escape) {
            if (in_quotes and i + 1 < data.len and data[i + 1] == state.escape) {
                i += 2; // Skip escaped quote
                continue;
            }
            in_quotes = !in_quotes;
        } else if (!in_quotes and (data[i] == '\n')) {
            last_complete = i + 1;
        }
        i += 1;
    }

    // Parse complete rows and return immediately (don't store terms in resource)
    var result: beam.term = beam.make(&[_]beam.term{}, .{});

    if (last_complete > 0) {
        const complete_data = data[0..last_complete];
        result = parseCSVFast(complete_data, Config{
            .separator = state.separator,
            .escape = state.escape,
        });

        // Remove parsed bytes from buffer
        const remaining_len = data.len - last_complete;
        if (remaining_len > 0) {
            std.mem.copyForwards(u8, state.buffer.items[0..remaining_len], data[last_complete..]);
        }
        state.buffer.shrinkRetainingCapacity(remaining_len);
    }

    // Persist state changes back to resource
    parser.update(state);
    return .{ result, state.buffer.items.len };
}

pub fn streaming_finalize(parser: StreamingParserResource) beam.term {
    var state = parser.unpack();

    // Parse any remaining buffer as final row(s)
    var result: beam.term = beam.make(&[_]beam.term{}, .{});

    if (state.buffer.items.len > 0) {
        result = parseCSVFast(state.buffer.items, Config{
            .separator = state.separator,
            .escape = state.escape,
        });
        state.buffer.clearRetainingCapacity();
    }

    // Persist state changes back to resource
    parser.update(state);
    return result;
}

pub fn streaming_status(parser: StreamingParserResource) struct { usize, bool } {
    const state = parser.unpack();
    return .{
        state.buffer.items.len,
        state.buffer.items.len > 0,
    };
}

// ============================================================================
// Strategy G: Chunk Parser (single-pass streaming)
// Parses complete rows from a chunk, returns (rows, bytes_consumed)
// Eliminates need for separate Elixir boundary detection
// ============================================================================

pub fn parse_chunk(input: []const u8) struct { beam.term, usize } {
    return parse_chunk_with_config(input, ',', '"');
}

pub fn parse_chunk_with_config(input: []const u8, separator: u8, escape: u8) struct { beam.term, usize } {
    if (input.len == 0) {
        return .{ beam.make(&[_]beam.term{}, .{}), 0 };
    }

    const config = Config{ .separator = separator, .escape = escape };

    // First pass: find last complete row boundary (quote-aware)
    var last_complete: usize = 0;
    var in_quotes = false;
    var scan_pos: usize = 0;

    while (scan_pos < input.len) {
        const c = input[scan_pos];
        if (c == config.escape) {
            if (in_quotes and scan_pos + 1 < input.len and input[scan_pos + 1] == config.escape) {
                scan_pos += 2; // Skip escaped quote
                continue;
            }
            in_quotes = !in_quotes;
        } else if (!in_quotes and c == '\n') {
            last_complete = scan_pos + 1;
        } else if (!in_quotes and c == '\r') {
            if (scan_pos + 1 < input.len and input[scan_pos + 1] == '\n') {
                last_complete = scan_pos + 2;
                scan_pos += 1; // Skip \n in next iteration
            } else {
                last_complete = scan_pos + 1;
            }
        }
        scan_pos += 1;
    }

    // No complete rows found
    if (last_complete == 0) {
        return .{ beam.make(&[_]beam.term{}, .{}), 0 };
    }

    // Parse complete rows using SIMD parser
    const complete_data = input[0..last_complete];
    const rows = parseCSVFast(complete_data, config);

    return .{ rows, last_complete };
}

// SIMD-accelerated version of parse_chunk
// Uses SIMD to find row boundaries, then parses in one pass
pub fn parse_chunk_simd(input: []const u8) struct { beam.term, usize } {
    return parse_chunk_simd_with_config(input, ',', '"');
}

pub fn parse_chunk_simd_with_config(input: []const u8, separator: u8, escape: u8) struct { beam.term, usize } {
    if (input.len == 0) {
        return .{ beam.make(&[_]beam.term{}, .{}), 0 };
    }

    const config = Config{ .separator = separator, .escape = escape };

    // Stack buffers for row and field terms
    const STACK_ROWS = 102400;
    var stack_rows: [STACK_ROWS]beam.term = undefined;
    var heap_rows: ?[]beam.term = null;
    var heap_capacity: usize = 0;
    defer if (heap_rows) |h| allocator.free(h);

    var row_count: usize = 0;
    var field_buf: [1024]beam.term = undefined;
    var unescape_buf: [65536]u8 = undefined;

    var pos: usize = 0;
    var last_row_end: usize = 0;

    while (pos < input.len) {
        var field_count: usize = 0;
        var row_done = false;
        var row_complete = false;

        // Parse fields in this row
        while (!row_done and field_count < field_buf.len and pos <= input.len) {
            if (pos < input.len and input[pos] == config.escape) {
                // Quoted field
                pos += 1;
                const content_start = pos;
                var needs_unescape = false;

                while (pos < input.len) {
                    const remaining = input[pos..];
                    if (simdFindByte(remaining, config.escape)) |offset| {
                        pos += offset + 1;
                        if (pos < input.len and input[pos] == config.escape) {
                            needs_unescape = true;
                            pos += 1;
                        } else {
                            break;
                        }
                    } else {
                        // No closing quote found - incomplete row
                        pos = input.len;
                        break;
                    }
                }

                // Check if we hit end of input without closing quote
                if (pos > input.len or (pos == input.len and (content_start >= input.len or input[pos - 1] != config.escape))) {
                    // Incomplete quoted field - revert to last complete row
                    break;
                }

                const content_end = if (pos > content_start) pos - 1 else content_start;
                const raw = input[content_start..content_end];

                if (needs_unescape) {
                    const len = unescapeInPlace(raw, config.escape, &unescape_buf);
                    field_buf[field_count] = beam.make(unescape_buf[0..len], .{});
                } else {
                    field_buf[field_count] = beam.make(raw, .{});
                }
            } else {
                // Unquoted field - SIMD scan
                const start = pos;
                if (start < input.len) {
                    const remaining = input[start..];
                    if (simdFindAny3(remaining, config.separator, '\n', '\r')) |offset| {
                        pos = start + offset;
                    } else {
                        pos = input.len;
                    }
                    field_buf[field_count] = beam.make(input[start..pos], .{});
                } else {
                    field_buf[field_count] = beam.make("", .{});
                }
            }

            field_count += 1;

            // Check for separator or end of row
            if (pos < input.len) {
                if (input[pos] == config.separator) {
                    pos += 1;
                    // Continue to next field
                } else if (input[pos] == '\r' or input[pos] == '\n') {
                    if (input[pos] == '\r') pos += 1;
                    if (pos < input.len and input[pos] == '\n') pos += 1;
                    row_done = true;
                    row_complete = true;
                }
            } else {
                // End of input without newline - incomplete row, don't include
                row_done = true;
                row_complete = false;
            }
        }

        if (row_complete and field_count > 0) {
            // Build field list using cons cells
            var field_list = beam.make_empty_list(.{});
            var i: usize = field_count;
            while (i > 0) {
                i -= 1;
                field_list = beam.make_list_cell(field_buf[i], field_list, .{});
            }

            // SmallVec-like storage
            if (row_count < STACK_ROWS) {
                stack_rows[row_count] = field_list;
            } else {
                if (heap_rows == null) {
                    heap_capacity = STACK_ROWS * 2;
                    heap_rows = allocator.alloc(beam.term, heap_capacity) catch break;
                    @memcpy(heap_rows.?[0..STACK_ROWS], &stack_rows);
                } else if (row_count >= heap_capacity) {
                    const new_capacity = heap_capacity * 2;
                    heap_rows = allocator.realloc(heap_rows.?, new_capacity) catch break;
                    heap_capacity = new_capacity;
                }
                heap_rows.?[row_count] = field_list;
            }
            row_count += 1;
            last_row_end = pos;
        } else if (!row_complete) {
            // Incomplete row - stop processing
            break;
        }
    }

    // Build row list
    var row_list = beam.make_empty_list(.{});
    var i: usize = row_count;

    if (heap_rows) |heap| {
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(heap[i], row_list, .{});
        }
    } else {
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(stack_rows[i], row_list, .{});
        }
    }

    return .{ row_list, last_row_end };
}

// Helper function kept for compatibility but no longer needed for streaming
fn countListLength(list: beam.term) usize {
    var count: usize = 0;
    var current = list;
    while (true) {
        const head, const tail = beam.get_list_cell(current, .{}) catch break;
        _ = head;
        count += 1;
        current = tail;
    }
    return count;
}

fn appendLists(list1: beam.term, list2: beam.term) beam.term {
    // Convert list1 to array, append list2
    var items: [102400]beam.term = undefined;
    var count: usize = 0;

    // Collect from list1
    var current = list1;
    while (count < items.len) {
        const head, const tail = beam.get_list_cell(current, .{}) catch break;
        items[count] = head;
        count += 1;
        current = tail;
    }

    // Collect from list2
    current = list2;
    while (count < items.len) {
        const head, const tail = beam.get_list_cell(current, .{}) catch break;
        items[count] = head;
        count += 1;
        current = tail;
    }

    return beam.make(items[0..count], .{});
}

// ============================================================================
// Strategy E: Parallel Parser
// ============================================================================

pub fn parse_string_parallel(input: []const u8) beam.term {
    return parse_string_parallel_with_config(input, ',', '"');
}

pub fn parse_string_parallel_with_config(input: []const u8, separator: u8, escape: u8) beam.term {
    return parseCSVFast(input, Config{ .separator = separator, .escape = escape });
}

// ============================================================================
// Strategy F: Zero-Copy Parser (true sub-binary implementation)
// ============================================================================

// Zero-copy parser that creates sub-binaries referencing the original input
fn parseCSVZeroCopy(input_term: beam.term, config: Config) beam.term {
    const env = beam.context.env;

    // Get binary data
    var bin: e.ErlNifBinary = undefined;
    if (e.enif_inspect_binary(env, input_term.v, &bin) == 0) {
        return beam.make(.@"error", .{});
    }

    const input = bin.data[0..bin.size];
    if (input.len == 0) {
        return beam.make(&[_]beam.term{}, .{});
    }

    // Uses global tracking allocator

    // SmallVec-like storage: stack first, spill to heap for large files
    const STACK_ROWS = 102400;
    var stack_rows: [STACK_ROWS]beam.term = undefined;
    var heap_rows: ?[]beam.term = null;
    var heap_capacity: usize = 0;
    defer if (heap_rows) |h| allocator.free(h);

    var row_count: usize = 0;

    // Stack buffer for field terms per row (support up to 1024 columns)
    var field_buf: [1024]beam.term = undefined;
    // Stack buffer for unescaping (only used when needed)
    var unescape_buf: [65536]u8 = undefined;

    var pos: usize = 0;

    while (pos <= input.len) {
        var field_count: usize = 0;
        var row_done = false;

        // Parse fields in this row
        while (!row_done and field_count < field_buf.len) {
            if (pos < input.len and input[pos] == config.escape) {
                // Quoted field
                pos += 1;
                const content_start = pos;
                var needs_unescape = false;

                while (pos < input.len) {
                    const remaining = input[pos..];
                    if (simdFindByte(remaining, config.escape)) |offset| {
                        pos += offset + 1;
                        if (pos < input.len and input[pos] == config.escape) {
                            needs_unescape = true;
                            pos += 1;
                        } else {
                            break;
                        }
                    } else {
                        pos = input.len;
                        break;
                    }
                }

                const content_end = if (pos > content_start) pos - 1 else content_start;

                if (needs_unescape) {
                    // Must copy and unescape
                    const raw = input[content_start..content_end];
                    const len = unescapeInPlace(raw, config.escape, &unescape_buf);
                    field_buf[field_count] = beam.make(unescape_buf[0..len], .{});
                } else {
                    // Zero-copy sub-binary!
                    field_buf[field_count] = .{ .v = e.enif_make_sub_binary(env, input_term.v, content_start, content_end - content_start) };
                }
            } else {
                // Unquoted field - SIMD scan
                const start = pos;
                if (start < input.len) {
                    const remaining = input[start..];
                    if (simdFindAny3(remaining, config.separator, '\n', '\r')) |offset| {
                        pos = start + offset;
                    } else {
                        pos = input.len;
                    }
                    // Zero-copy sub-binary!
                    field_buf[field_count] = .{ .v = e.enif_make_sub_binary(env, input_term.v, start, pos - start) };
                } else {
                    // Empty field at end of input
                    field_buf[field_count] = beam.make("", .{});
                }
            }

            field_count += 1;

            // Check for separator or end of row
            if (pos < input.len) {
                if (input[pos] == config.separator) {
                    pos += 1;
                    // Continue to next field
                } else if (input[pos] == '\r' or input[pos] == '\n') {
                    if (input[pos] == '\r') pos += 1;
                    if (pos < input.len and input[pos] == '\n') pos += 1;
                    row_done = true;
                }
            } else {
                // End of input
                row_done = true;
            }
        }

        if (field_count > 0) {
            // Build field list using cons cells
            var field_list = beam.make_empty_list(.{});
            var i: usize = field_count;
            while (i > 0) {
                i -= 1;
                field_list = beam.make_list_cell(field_buf[i], field_list, .{});
            }

            // SmallVec-like storage: stack first, spill to heap if needed
            if (row_count < STACK_ROWS) {
                // Fast path: store on stack
                stack_rows[row_count] = field_list;
            } else {
                // Slow path: spill to heap
                if (heap_rows == null) {
                    // First spill: allocate heap and copy stack contents
                    heap_capacity = STACK_ROWS * 2;
                    heap_rows = allocator.alloc(beam.term, heap_capacity) catch {
                        // Allocation failed, return what we have
                        break;
                    };
                    @memcpy(heap_rows.?[0..STACK_ROWS], &stack_rows);
                } else if (row_count >= heap_capacity) {
                    // Need to grow heap buffer
                    const new_capacity = heap_capacity * 2;
                    heap_rows = allocator.realloc(heap_rows.?, new_capacity) catch break;
                    heap_capacity = new_capacity;
                }
                heap_rows.?[row_count] = field_list;
            }
            row_count += 1;
        }

        // Exit if we've consumed all input
        if (pos >= input.len) break;
    }

    // Build row list using cons cells from the appropriate buffer
    var row_list = beam.make_empty_list(.{});
    var i: usize = row_count;

    if (heap_rows) |heap| {
        // Large file: read from heap buffer
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(heap[i], row_list, .{});
        }
    } else {
        // Small file: read from stack buffer
        while (i > 0) {
            i -= 1;
            row_list = beam.make_list_cell(stack_rows[i], row_list, .{});
        }
    }

    return row_list;
}

pub fn parse_string_zero_copy(input: beam.term) beam.term {
    return parse_string_zero_copy_with_config(input, ',', '"');
}

pub fn parse_string_zero_copy_with_config(input: beam.term, separator: u8, escape: u8) beam.term {
    return parseCSVZeroCopy(input, Config{ .separator = separator, .escape = escape });
}

// ============================================================================
// Test function
// ============================================================================

pub fn nif_loaded() bool {
    return true;
}
